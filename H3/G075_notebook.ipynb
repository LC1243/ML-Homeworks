{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbccfaed",
   "metadata": {},
   "source": [
    "### Consider the winequality-red.csv dataset (available at the webpage) where the goal is to estimate the quality (sensory appreciation) of a wine based on physicochemical inputs. \n",
    "### Using a 80-20 training-test split with a fixed seed (random_state=0), you are asked to learn MLP regressors to answer the following questions.\n",
    "### Given their stochastic behavior, average the performance of each MLP from 10 runs (for reproducibility consider seeding the MLPs with random_state âˆˆ {1. .10})."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fd55c",
   "metadata": {},
   "source": [
    "### 1) [3.5v] Learn a MLP regressor with 2 hidden layers of size 10, rectifier linear unit activation on all nodes, and early stopping with 20% of training data set aside for validation. All remaining parameters (e.g., loss, batch size, regularization term, solver) should be set as default. Plot the distribution of the residues (in absolute value) using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6230e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00815306030158447"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "X, y = make_regression(n_samples=200, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "###\n",
    "# FIXME - random states pertence a {1,...,10}\n",
    "###\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10), activation = 'relu', random_state=1,\\\n",
    "                   early_stopping = True, validation_fraction = 0.2,\\\n",
    "                   max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "# mlp.predict(X_test[:2])\n",
    "# mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705ae2b",
   "metadata": {},
   "source": [
    "### 2) [1.5v] Since we are in the presence of a integer regression task, a recommended trick is to round and bound estimates. Assess the impact of these operations on the MAE of the MLP learnt in previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3811864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f3917",
   "metadata": {},
   "source": [
    "### 3) [1.5v] Similarly assess the impact on RMSE from replacing early stopping by a well-defined number of iterations in {20,50,100,200} (where one iteration corresponds to a batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbaac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9deda504",
   "metadata": {},
   "source": [
    "### 3) [1.5v] Critically comment the results obtained in previous question, hypothesizing at least one reason why early stopping favors and/or worsens performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d3686",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
